# ğŸ“Š Sistema de AnÃ¡lisis de Tendencias AcadÃ©micas - UDLA

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-13+-blue.svg)
![Selenium](https://img.shields.io/badge/Selenium-4.0+-green.svg)

*Sistema automatizado para anÃ¡lisis de viabilidad de programas acadÃ©micos mediante web scraping y anÃ¡lisis de datos*

</div>

---

## ğŸ“‹ Tabla de Contenidos

- [ğŸ¯ DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
- [ğŸ—ï¸ Arquitectura del Sistema](#ï¸-arquitectura-del-sistema)
- [ğŸš€ CaracterÃ­sticas Principales](#-caracterÃ­sticas-principales)
- [ğŸ“¦ InstalaciÃ³n](#-instalaciÃ³n)
- [âš™ï¸ ConfiguraciÃ³n](#ï¸-configuraciÃ³n)
- [ğŸ–¥ï¸ Uso del Sistema](#ï¸-uso-del-sistema)
- [ğŸ¤– Sistema de Scrapers](#-sistema-de-scrapers)
- [ğŸ“Š MÃ³dulos de AnÃ¡lisis](#-mÃ³dulos-de-anÃ¡lisis)
- [ğŸ—„ï¸ Base de Datos](#ï¸-base-de-datos)
- [ğŸ“ˆ GeneraciÃ³n de Reportes](#-generaciÃ³n-de-reportes)
- [ğŸ”§ Troubleshooting](#-troubleshooting)
- [ğŸ‘¥ ContribuciÃ³n](#-contribuciÃ³n)

---

## ğŸ¯ DescripciÃ³n del Proyecto

Este sistema automatizado estÃ¡ diseÃ±ado para **analizar la viabilidad de nuevos programas acadÃ©micos** mediante la recopilaciÃ³n y anÃ¡lisis de datos de mÃºltiples fuentes web. Utiliza tÃ©cnicas de web scraping, anÃ¡lisis de datos y machine learning para proporcionar insights valiosos sobre tendencias educativas.

### ğŸŒŸ Objetivos Principales

- **ğŸ“ˆ AnÃ¡lisis de Mercado**: Evaluar la demanda del mercado laboral
- **ğŸ” InvestigaciÃ³n de Competencia**: Analizar programas similares existentes
- **ğŸ“Š Tendencias de BÃºsqueda**: Monitorear interÃ©s pÃºblico en Ã¡reas especÃ­ficas
- **ğŸ’¼ Oportunidades Laborales**: Evaluar demanda profesional en LinkedIn

---

## ğŸ—ï¸ Arquitectura del Sistema

```mermaid
graph TB
    A[ğŸ–¥ï¸ Interfaz Streamlit] --> B[ğŸ“ Formularios de Entrada]
    B --> C[ğŸ—„ï¸ Base de Datos PostgreSQL]
    C --> D[âš¡ Cola de Scrapers]
    D --> E[ğŸ¤– Worker Scraper]
    E --> F[ğŸ”— LinkedIn Scraper]
    E --> G[ğŸ” SEMrush Scraper]
    F --> H[ğŸ“Š AnÃ¡lisis de Datos]
    G --> H
    H --> I[ğŸ“ˆ GeneraciÃ³n de Reportes]
    I --> A
```

### ğŸ§© Componentes Principales

| Componente              | DescripciÃ³n               | TecnologÃ­a                           |
| ----------------------- | -------------------------- | ------------------------------------- |
| **Frontend**      | Interfaz web interactiva   | ğŸš€ Streamlit                          |
| **Backend**       | LÃ³gica de negocio y API   | ğŸ Python                             |
| **Base de Datos** | Almacenamiento persistente | ğŸ˜ PostgreSQL                         |
| **Scrapers**      | AutomatizaciÃ³n web        | ğŸŒ Selenium + Undetected ChromeDriver |
| **AnÃ¡lisis**     | Procesamiento de datos     | ğŸ“Š Pandas + NumPy                     |

---

## ğŸš€ CaracterÃ­sticas Principales

### âœ¨ Funcionalidades Core

- **ğŸ¯ GestiÃ³n de Proyectos**: Crear, editar y eliminar proyectos de anÃ¡lisis
- **ğŸ¤– Scraping Automatizado**: RecopilaciÃ³n automÃ¡tica de datos web
- **ğŸ“Š AnÃ¡lisis Multi-dimensional**: EvaluaciÃ³n desde 4 perspectivas clave
- **ğŸ“ˆ Reportes Visuales**: GrÃ¡ficos interactivos y presentaciones
- **â° Cola de Procesamiento**: Sistema de colas con prioridades
- **ğŸ”„ Monitoreo en Tiempo Real**: Estado de procesos en vivo

### ğŸ›¡ï¸ CaracterÃ­sticas TÃ©cnicas

- **ğŸ”’ Manejo de Sesiones**: Persistencia de sesiones de Chrome
- **ğŸš« Anti-detecciÃ³n**: TÃ©cnicas avanzadas para evitar bloqueos
- **ğŸ“± Responsive Design**: Interfaz adaptable a diferentes dispositivos
- **ğŸ”„ Reintentos AutomÃ¡ticos**: Manejo robusto de errores
- **ğŸ“ Logging Detallado**: Trazabilidad completa de procesos

---

## ğŸ“¦ InstalaciÃ³n

### ğŸ“‹ Requisitos del Sistema

- **ğŸ Python**: 3.8 o superior
- **ğŸ˜ PostgreSQL**: 13 o superior
- **ğŸŒ Google Chrome**: Ãšltima versiÃ³n
- **ğŸ’¾ RAM**: MÃ­nimo 8GB recomendado
- **ğŸ’¿ Espacio**: 5GB libres

### ğŸ”§ InstalaciÃ³n Paso a Paso

1. **ğŸ“¥ Clonar el repositorio**

```bash
git clone https://github.com/tu-usuario/estudio-tendencia.git
cd estudio-tendencia
```

2. **ğŸ Crear entorno virtual**

```bash
python -m venv venv
venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac
```

3. **ğŸ“¦ Instalar dependencias**

```bash
pip install -r requirements.txt
```

4. **ğŸ—„ï¸ Configurar base de datos**

```bash
# Crear base de datos en PostgreSQL
createdb estudio_tendencias
```

5. **ğŸ“„ Ejecutar scripts SQL**

```bash
psql -d estudio_tendencias -f database/schema.sql
```

---

## âš™ï¸ ConfiguraciÃ³n

### ğŸ” Variables de Entorno

Crear archivo `.env` en la raÃ­z del proyecto:

```env
# ğŸ—„ï¸ Base de Datos
DB_HOST=localhost
DB_PORT=5432
DB_NAME=estudio_tendencias
DB_USER=tu_usuario
DB_PASSWORD=tu_password

# ğŸ”— LinkedIn
LINKEDIN_USER=tu_email@example.com
LINKEDIN_PASS=tu_password

# ğŸ” SEMrush
SEMRUSH_USER=tu_email@example.com
SEMRUSH_PASS=tu_password

# âš¡ Worker Configuration
WORKER_POLL_SECONDS=5
```

### ğŸ› ï¸ ConfiguraciÃ³n de Chrome

El sistema utiliza un perfil de Chrome personalizado ubicado en:

```
C:\Users\User\Documents\TRABAJO - UDLA\Estudio-Tendencia\profile
```

---

## ğŸ–¥ï¸ Uso del Sistema

### ğŸš€ Iniciar la AplicaciÃ³n

```bash
streamlit run app.py
```

La aplicaciÃ³n estarÃ¡ disponible en: `http://localhost:8501`

### ğŸ“ Flujo de Trabajo

#### 1. **ğŸ“‹ Crear Proyecto**

- Acceder a la secciÃ³n "Formulario"
- Completar datos del proyecto:
  - ğŸ“ Tipo de carpeta (Pregrado/Posgrado)
  - ğŸ¯ Carrera de referencia
  - ğŸ“š Carrera de estudio
  - ğŸ” Palabra clave SEMrush
  - ğŸ“Š CÃ³digo CIIU
  - ğŸ“ˆ Tendencias de Google

#### 2. **âš¡ Procesamiento AutomÃ¡tico**

- El sistema encola automÃ¡ticamente el proyecto
- Los scrapers procesan la informaciÃ³n
- Se puede monitorear el estado en tiempo real

#### 3. **ğŸ“Š AnÃ¡lisis de Resultados**

- Ver tabla de evaluaciÃ³n
- Generar reportes visuales
- Exportar presentaciones

---

## ğŸ¤– Sistema de Scrapers

### ğŸ”„ Worker Principal (`worker_scraper.py`)

El worker principal coordina todo el proceso de scraping:

```python
# ğŸ§¹ Limpieza de perfil por proyecto
# ğŸ”— EjecuciÃ³n de LinkedIn scraper
# ğŸ” EjecuciÃ³n de SEMrush scraper
# ğŸ“Š Manejo de errores y reintentos
```

### ğŸ”— LinkedIn Scraper

**Funcionalidades:**

- ğŸ” Login automÃ¡tico
- ğŸ“ NavegaciÃ³n por carpetas
- ğŸ“Š ExtracciÃ³n de datos de reportes
- ğŸŒ AnÃ¡lisis por regiones (Ecuador, AmÃ©rica Latina)

**Datos extraÃ­dos:**

- ğŸ‘¥ NÃºmero de profesionales
- ğŸ’¼ Anuncios de empleo
- ğŸ“ˆ Porcentaje de demanda

### ğŸ” SEMrush Scraper

**Funcionalidades:**

- ğŸ” Login automÃ¡tico
- ğŸ” BÃºsqueda de palabras clave
- ğŸ“Š ExtracciÃ³n de mÃ©tricas SEO

**Datos extraÃ­dos:**

- ğŸ‘ï¸ VisiÃ³n general de bÃºsquedas
- ğŸ”¤ NÃºmero de palabras clave
- ğŸ“Š Volumen de bÃºsqueda

---

## ğŸ“Š MÃ³dulos de AnÃ¡lisis

### ğŸ” BÃºsqueda Web (35%)

Combina datos de **SEMrush** y **Google Trends**:

```python
# ğŸ“ˆ SEMrush: 15% del total
# ğŸ“Š Google Trends: 20% del total
# ğŸ¯ Resultado: InterÃ©s de bÃºsqueda web
```

### ğŸ”— LinkedIn (25%)

Analiza demanda profesional:

```python
# ğŸ‘¥ Profesionales registrados
# ğŸ’¼ Anuncios de empleo activos
# ğŸ“ˆ Ratio de demanda/oferta
```

### ğŸ¢ Competencia (25%)

EvalÃºa programas similares:

```python
# ğŸ“ Modalidad presencial
# ğŸ’» Modalidad virtual
# ğŸ“Š AnÃ¡lisis comparativo
```

### ğŸ’° Mercado (15%)

AnÃ¡lisis econÃ³mico sectorial:

```python
# ğŸ’¼ Ingresos totales del sector
# ğŸ“ˆ Ventas anuales
# ğŸ¯ CÃ³digos CIIU especÃ­ficos
```

---

## ğŸ—„ï¸ Base de Datos

### ğŸ“‹ Tablas Principales

| Tabla                    | DescripciÃ³n             | Campos Clave                                  |
| ------------------------ | ------------------------ | --------------------------------------------- |
| `proyectos_tendencias` | ğŸ“Š Proyectos principales | `id`, `carrera_estudio`, `tipo_carpeta` |
| `linkedin`             | ğŸ”— Datos de LinkedIn     | `profesionales`, `anuncios_empleo`        |
| `semrush`              | ğŸ” Datos de SEMrush      | `vision_general`, `palabras`, `volumen` |
| `tendencias`           | ğŸ“ˆ Google Trends         | `palabra`, `promedio`                     |
| `scraper_queue`        | âš¡ Cola de procesamiento | `status`, `priority`, `proyecto_id`     |

### ğŸ”„ Estados de Procesamiento

| Estado        | DescripciÃ³n | Icono |
| ------------- | ------------ | ----- |
| `queued`    | En cola      | â³    |
| `running`   | Procesando   | ğŸŸ¡    |
| `completed` | Completado   | ğŸŸ¢    |
| `failed`    | Error        | ğŸ”´    |

---

## ğŸ“ˆ GeneraciÃ³n de Reportes

### ğŸ“Š Tabla de EvaluaciÃ³n

Muestra resultados por modalidad:

- **ğŸ“ DistribuciÃ³n**: Pesos de cada factor
- **ğŸ“ Presencialidad**: Resultados modalidad presencial
- **ğŸ’» Virtualidad**: Resultados modalidad virtual
- **ğŸ¯ Total**: PuntuaciÃ³n final

### ğŸ“‹ Rangos de EvaluaciÃ³n

| Rango      | EvaluaciÃ³n              | Color |
| ---------- | ------------------------ | ----- |
| 0% - 60%   | âŒ No Viable             | ğŸ”´    |
| 61% - 70%  | âš ï¸ RevisiÃ³n Adicional | ğŸŸ¡    |
| 71% - 100% | âœ… Viable                | ğŸŸ¢    |

### ğŸ“Š Reportes Visuales

- **ğŸ“ˆ GrÃ¡ficos de radar**: ComparaciÃ³n multi-dimensional
- **ğŸ“‹ Tablas dinÃ¡micas**: Datos detallados
- **ğŸ¨ Presentaciones**: Formato exportable

---

## ğŸ”§ Troubleshooting

### â“ Problemas Comunes

#### ğŸŒ Error de ConexiÃ³n a Sitios Web

**SÃ­ntomas**: Timeout o bloqueo de acceso
**SoluciÃ³n**:

```bash
# ğŸ§¹ Limpiar perfil de Chrome
python -c "from scrapers.linkedin_modules.driver_config import limpiar_perfil_completo; limpiar_perfil_completo('profile', 'Default')"
```

#### ğŸ—„ï¸ Error de Base de Datos

**SÃ­ntomas**: "Connection refused" o errores SQL
**SoluciÃ³n**:

```bash
# âœ… Verificar conexiÃ³n
pg_isready -h localhost -p 5432
# ğŸ”„ Reiniciar servicio PostgreSQL
```

#### ğŸ¤– Scraper Atascado

**SÃ­ntomas**: Estado "running" por mÃ¡s de 10 minutos
**SoluciÃ³n**:

- El sistema automÃ¡ticamente reintenta trabajos atascados
- Verificar logs del worker para mÃ¡s detalles

### ğŸ“ Logs y Debugging

```bash
# ğŸ‘€ Ver logs del worker
python worker_scraper.py

# ğŸ” Ejecutar scraper individual
python scrapers/linkedin.py [proyecto_id]
python scrapers/semrush.py [proyecto_id]
```

---

## ğŸ› ï¸ Desarrollo y Mantenimiento

### ğŸ—ï¸ Estructura del Proyecto

```
ğŸ“ Estudio-Tendencia/
â”œâ”€â”€ ğŸ“„ app.py                     # AplicaciÃ³n principal Streamlit
â”œâ”€â”€ ğŸ¤– worker_scraper.py          # Worker de scrapers
â”œâ”€â”€ ğŸ“ scrapers/                  # MÃ³dulos de scraping
â”‚   â”œâ”€â”€ ğŸ”— linkedin.py
â”‚   â”œâ”€â”€ ğŸ” semrush.py
â”‚   â””â”€â”€ ğŸ“ linkedin_modules/      # MÃ³dulos LinkedIn
â”œâ”€â”€ ğŸ“ data_process/              # MÃ³dulos de anÃ¡lisis
â”‚   â”œâ”€â”€ ğŸ” busquedaWeb.py
â”‚   â”œâ”€â”€ ğŸ”— linkedin.py
â”‚   â”œâ”€â”€ ğŸ’° mercado.py
â”‚   â””â”€â”€ ğŸ¢ competencia.py
â”œâ”€â”€ ğŸ“ forms/                     # Formularios web
â”œâ”€â”€ ğŸ“ pages/                     # PÃ¡ginas de la aplicaciÃ³n
â””â”€â”€ ğŸ“ profile/                   # Perfil de Chrome
```

### ğŸ§ª Testing

```bash
# ğŸ§ª Ejecutar tests unitarios
python -m pytest tests/

# ğŸ” Test de scraper especÃ­fico
python tests/test_linkedin.py
```

---

## ğŸ‘¥ ContribuciÃ³n

### ğŸ¤ CÃ³mo Contribuir

1. ğŸ´ Fork del repositorio
2. ğŸŒ¿ Crear rama feature (`git checkout -b feature/nueva-funcionalidad`)
3. ğŸ’¾ Commit cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. ğŸ“¤ Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. ğŸ”€ Crear Pull Request

### ğŸ“‹ EstÃ¡ndares de CÃ³digo

- **ğŸ PEP 8**: Seguir estÃ¡ndares de Python
- **ğŸ“ DocumentaciÃ³n**: Comentarios claros y docstrings
- **ğŸ§ª Testing**: Incluir tests para nuevas funcionalidades
- **ğŸ”§ Logging**: Usar logging apropiado para debugging

---

## ğŸ˜ŠSoporte

Para soporte tÃ©cnico o preguntas:

- ğŸ“š **DocumentaciÃ³n**: Ver secciÃ³n de troubleshooting
- ğŸ› **Reportar bugs**: Crear issue en el repositorio

---

<div align="center">

**ğŸ“ Desarrollado para Universidad de las AmÃ©ricas (UDLA)**

*Sistema de AnÃ¡lisis de Tendencias AcadÃ©micas*

![UDLA](https://img.shields.io/badge/UDLA-2024-red.svg)

</div>
